{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPWDJsaLTf/N2JHwcRf13pk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"QcRuTKMszly2"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","import os\n","from keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras import Model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import layers\n"],"metadata":{"id":"V9T-Tvw81jmG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install gradio"],"metadata":{"id":"-JivPXdnQeSS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gradio as gr"],"metadata":{"id":"hQQ1ngu3Qsss"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dir='/content/drive/MyDrive/Android-App-Skin-Cancer-Detector/Training/Dataset'"],"metadata":{"id":"hcEN396Z1ooo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Labels = ['Benign','Malignant']"],"metadata":{"id":"WD3bQykO2QEQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print (\"class : \")\n","for i in range(len(Labels)):\n","    print (i, end = \" \")\n","    print (Labels[i])"],"metadata":{"id":"kyvSEGWI2Vg_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Number of classes:',len(Labels))"],"metadata":{"id":"p0nOiq_12Xoc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["module_selection = (\"mobilenet_v2\", 224, 1280)\n","handle_base, pixels, FV_SIZE = module_selection\n","MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/2\".format(handle_base)\n","IMAGE_SIZE = (pixels, pixels)\n","BATCH_SIZE = 16"],"metadata":{"id":"KXbkokfj2dPO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IMAGE_SIZE"],"metadata":{"id":"828uacjS2rTJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","      rescale = 1./255,\n","      rotation_range=40,\n","      horizontal_flip=True,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      shear_range=0.2,\n","      zoom_range=0.2,\n","      fill_mode='nearest',\n","      validation_split=0.4)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    subset=\"training\",\n","    shuffle=True,\n","    seed=42,\n","    color_mode=\"rgb\",\n","    class_mode=\"categorical\",\n","    target_size=IMAGE_SIZE,\n","    batch_size=BATCH_SIZE)\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    shuffle=False,\n","    seed=42,\n","    color_mode=\"rgb\",\n","    class_mode=\"categorical\",\n","    subset=\"validation\",\n","    target_size=IMAGE_SIZE,\n","    batch_size=BATCH_SIZE)"],"metadata":{"id":"xipRWpYA25UY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_extractor = hub.KerasLayer(MODULE_HANDLE,input_shape=IMAGE_SIZE+(3,), output_shape=[FV_SIZE]  )\n"],"metadata":{"id":"lz01bmFg3BID"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["do_fine_tuning = False\n","if do_fine_tuning:\n","  feature_extractor.trainable = True\n","  for layer in base_model.layers[-30:]:\n","    layer.trainable =True\n","\n","else:\n","  feature_extractor.trainable = False"],"metadata":{"id":"nFml-Szs3qTO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Building model with\", MODULE_HANDLE)\n","model = tf.keras.Sequential([\n","    feature_extractor,\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dropout(rate=0.2),\n","    tf.keras.layers.Dense(train_generator.num_classes, activation='softmax',\n","                           kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n","])\n","#model.build((None,)+IMAGE_SIZE+(3,))\n","\n","model.summary()"],"metadata":{"id":"7j2chVkV3vB-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LEARNING_RATE = 0.001\n","model.compile(\n","   optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n","   loss='categorical_crossentropy',\n","   metrics=['accuracy'])"],"metadata":{"id":"s9ae1RxY4dtU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS=15\n","history = model.fit(\n","        train_generator,\n","        steps_per_epoch=train_generator.samples//train_generator.batch_size,\n","        epochs=EPOCHS,\n","        validation_data=validation_generator,\n","        validation_steps=validation_generator.samples//validation_generator.batch_size)"],"metadata":{"id":"w2zLjFxh4i7y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pylab as plt\n","import numpy as np\n","\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(EPOCHS)\n","\n","plt.figure(figsize=(10, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","plt.ylabel(\"Accuracy (training and validation)\")\n","plt.xlabel(\"Training Steps\")\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.ylabel(\"Loss (training and validation)\")\n","plt.xlabel(\"Training Steps\")\n","plt.show()"],"metadata":{"id":"O534eBaN5ESP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import cv2\n","def upload(filename):\n","    img = cv2.imread(os.path.join(train_dir, filename))\n","    img = cv2.resize(img, (224, 224) )\n","    img = img /255\n","\n","    return img\n","\n","def pre_result(image):\n","    x = model.predict(np.asarray([img]))[0]\n","    classx = np.argmax(x)\n","\n","    return {Labels[classx]: x[classx]}\n","\n","images = random.sample(validation_generator.filenames, 16)\n","\n","for idx, filename in enumerate(images):\n","\n","\n","    img = upload(filename)\n","    prediction = pre_result(img)\n","    print(\"class: %s, confidence: %f\" % (list(prediction.keys())[0], list(prediction.values())[0]))\n","    plt.imshow(img)\n","    plt.figure(idx)\n","    plt.show()"],"metadata":{"id":"oVUC7WPN5UI-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_image(img):\n","  img_4d=img.reshape(-1,224,224,3)\n","  prediction=model.predict(img_4d)[0]\n","  return {Labels[i]: float(prediction[i]) for i in range(len(Labels))}"],"metadata":{"id":"eZNTGMOsOndF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = gr.inputs.Image(shape=(224,224))\n","label = gr.outputs.Label(num_top_classes=len(Labels))\n","\n","gr.Interface(fn=predict_image, inputs=image, outputs=label,interpretation='default').launch(debug='True')"],"metadata":{"id":"D2MG5YC-PW4j"},"execution_count":null,"outputs":[]}]}